---
title: Text as data (Optional)
teaching: 30
exercises: 15
source: Rmd
---

```{r setup, include=FALSE}
#Load required packages

require(quanteda)
require(ggplot2)
require(tidyverse)
require(here)
require(quanteda.textstats)
#install.packages("quanteda.textplots",dependencies =T,repos = "http://cran.us.r-project.org")
#install.packages("udpipe",dependencies =T,repos = "http://cran.us.r-project.org")
#install.packages("spacyr",dependencies =T,repos = "http://cran.us.r-project.org")
require(quanteda.textplots)
require(udpipe)
require(spacyr)

```

:::: instructor

- This is an optional lesson intended to introduce approaches to text as data by applying
  key concepts from corpus linguistics and natural language processing, with a focus on using
   computational approaches to qualitatively oriented discourse analysis.
- Note that his lesson was community-contributed and remains a work in progress. As such, it could
  benefit from feedback from instructors and/or workshop participants.

::::::::::::

::::::::::::::::::::::::::::::::::::::: objectives

- Introduce key concepts needed to use the **`quanteda`** package for discourse analysis 
i.e. corpus, tokens, dfm, frequency, collocation, keyness, concordance.
- Prepare text for analysis with the **`quanteda`** functions `corpus`, `tokens`, `dfm`, and `dfm_remove`.
- Investigate the most frequent features in a dfm using the **`quanteda`** function `textstat_frequency` and .
- Plot frequencies using **`ggplot`** 
- Select and modify a list of stopwords to remove unwanted words, query terms and spam from a dataset. 
- Visualise frequencies as a wordcloud using the **`quanteda`** function `textplot_wordcloud` and the **`wordcloud2`** function  `wordcloud2`.
- Identify the strengths and weaknesses of these approaches to visualising text data.
- Use `summarize`, `group_by`, and `count` to split a dataframe into groups of observations, apply a summary statistics for each group, and then combine the results.


::::::::::::::::::::::::::::::::::::::::::::::::::

:::::::::::::::::::::::::::::::::::::::: questions

- What are the most important concepts for automating text analysis?
- How can I prepare text data for analysis?
- How can I visualise frequency, collocation and concordance for a corpus of textual data?

::::::::::::::::::::::::::::::::::::::::::::::::::
## Load required packages



```{r}
texts <- c("I have fought against white domination", "and I have fought against black domination")
d <- tokens(texts) %>%
  dfm()

convert(d, "matrix") 
```


## Use the quanteda package to ...

```{r, message=FALSE}
library(quanteda)
```




:::::::::::::::::::::::::::::::::::::::: keypoints

- JSON is a popular data format for transferring data used by a great many Web based APIs
- The complex structure of a JSON document means that it cannot easily be 'flattened' into tabular data
- We can use R code to extract values of interest and place them in a csv file

::::::::::::::::::::::::::::::::::::::::::::::::::


